{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0746ed0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTN - > TO start coding in this NOTEBOOK & following FNS :::  run ::: hi_jupy()\n",
      "ATTN at the end RUN > py and cleans py ready to be copied >  runpy()\n",
      "ATTN - > TO get all GLOBAL, libs and functions & ALL_DATA inputs, stats, temp, tables files info > db_paths()\n",
      "ATTN - > TO move files from input to curr_direc > move_files(input_folder_path, curr_direc)\n",
      "ATTN - > TO COPY program > copy_files_and_subdirectories(path_2_copy, dest_direc) --- respects original copied\n",
      "ATTN - > TO get all GAME PLANS TO EXPORT ALPHA and BETA programs  > game_plan()\n",
      "define program_folder_name before running runpy()\n"
     ]
    }
   ],
   "source": [
    "exec(open(f\"/Users/yerik/_apple_source/PY/GLOBAL/_1_paths.py\",encoding=\"utf-8\").read()) #paths\n",
    "#direc= curr_direc ;# hi_jupy() \n",
    "# curr_direc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e006ba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.utils import mediainfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a556e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yerik/Desktop/input/ms_podcast/vr.wav'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{desk_path}/input/ms_podcast/vr.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a07b7fd",
   "metadata": {},
   "source": [
    "### importing and converting the audio file to WAV format would be to perform an initial analysis of the audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "329d74a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yerik/Desktop/input/ms_podcast/vr.wav'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.utils import mediainfo\n",
    "exec(open(f\"functions.py\",encoding=\"utf-8\").read()) #paths\n",
    "\n",
    "\n",
    "f'{desk_path}/input/ms_podcast/vr.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7296d6e",
   "metadata": {},
   "source": [
    "# 0 VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "550a6075",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_noise_reduction = 1.0 \n",
    "#(1.0)   Default, no extra reduction),\n",
    "#1.5)  # More aggressive reduction\n",
    "# 0.8)  # Less aggressive reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e06a5d",
   "metadata": {},
   "source": [
    "# 0 VARIABLES AVOBE\n",
    "# 1 START PROCESSING BY GETTING A CLEAN WAV BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86521f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been converted and saved at /Users/yerik/Desktop/output/ms_podcast/vr.wav\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "#convert_to_wav(\"input.mp3\", \"output.wav\")\n",
    "\n",
    "convert_to_wav(f'{desk_path}/input/ms_podcast/vr.wav', f'{desk_path}/output/ms_podcast/vr.wav')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4209d901",
   "metadata": {},
   "source": [
    "## 2.0  >>  Calculate the length of the audio in seconds and minutes.\n",
    "## 2.1 >> Determine the number of channels (Mono/Stereo).\n",
    "## 2.2 >> Retrieve the frame rate and other properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bb46133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio duration: 165.900952 seconds\n",
      "Channels: 2\n",
      "Frame rate: 44100 Hz\n",
      "\n",
      "\n",
      " 165.900952 2 44100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "length, channels, frame_rate = analyze_audio(f'{desk_path}/output/ms_podcast/vr.wav')  # ^^^ path ^^^\n",
    "print('\\n\\n',length, channels, frame_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb67c15",
   "metadata": {},
   "source": [
    "## 3 >> NOISE REDUTCTION (basic and adjustable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ad4f03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4bcb5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise-reduced audio saved at /Users/yerik/Desktop/output/ms_podcast/vr_noise_reduced.wav\n"
     ]
    }
   ],
   "source": [
    "# BASIC \n",
    "input_path = f'{desk_path}/input/ms_podcast/vr.wav'\n",
    "output_path = f'{desk_path}/output/ms_podcast/vr_noise_reduced.wav'\n",
    "\n",
    "basic_noise_reduction(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a736810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise-reduced audio saved at /Users/yerik/Desktop/output/ms_podcast/vr_noise_reduced.wav\n",
      "Your Choice was 1.0, \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ADJUSTABLE \n",
    "input_path = f'{desk_path}/input/ms_podcast/vr.wav'\n",
    "output_path = f'{desk_path}/output/ms_podcast/vr_noise_reduced.wav'\n",
    "\n",
    "adjustable_noise_reduction(input_path, output_path, threshold_factor=input_noise_reduction)  # Less aggressive reduction\n",
    "print(f'Your Choice was {input_noise_reduction}, \\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880ac992",
   "metadata": {},
   "source": [
    "# STEM extraction \n",
    "!python -m demucs.separate -d cpu \"/Users/yerik/Desktop/output/ms_podcast/tostem.wav\" -o \"/Users/yerik/Desktop/output/ms_podcast/STEMS\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d54a6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy STEM VOCAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eca02e",
   "metadata": {},
   "source": [
    "Explanation\n",
    "butter_highpass: Creates a high-pass filter using Butterworth design parameters.\n",
    "Input: cutoff frequency, sampling rate, order of the filter.\n",
    "Output: Filter coefficients a and b.\n",
    "highpass_filter: Applies the high-pass filter to audio data.\n",
    "Input: audio data, cutoff frequency, sampling rate, order of the filter, and threshold factor for aggressive filtering.\n",
    "Output: Filtered audio data.\n",
    "adjustable_noise_reduction: A wrapper function that allows users to adjust the noise reduction parameters.\n",
    "Input: input_path for the input .wav file, output_path for the output .wav file, and threshold_factor for more or less aggressive noise reduction.\n",
    "Output: Writes the filtered data into a .wav file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10aacc2",
   "metadata": {},
   "source": [
    "# Hight PASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "515ddea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "from scipy.signal import butter, filtfilt\n",
    "import numpy as np\n",
    "\n",
    "def adjustable_highpass_filter(input_path, output_path, cutoff_frequency, filter_order, threshold_factor):\n",
    "\n",
    "    def butter_highpass(cutoff, fs, order=5):\n",
    "        nyquist = 0.5 * fs\n",
    "        normal_cutoff = cutoff / nyquist\n",
    "        b, a = butter(order, normal_cutoff, btype='high', analog=False)\n",
    "        return b, a\n",
    "\n",
    "    def highpass_filter(data, cutoff, fs, order=5, threshold_factor=1):\n",
    "        b, a = butter_highpass(cutoff, fs, order=order)\n",
    "        y = filtfilt(b, a, data)\n",
    "        y = np.where(np.abs(y) > threshold_factor * np.max(np.abs(y)), y, 0)\n",
    "        return y.astype(np.int16)\n",
    "\n",
    "    # Read the input audio file\n",
    "    fs, data = wavfile.read(input_path)  # ^^^ path ^^^\n",
    "    \n",
    "    # Check if the audio is stereo\n",
    "    if len(data.shape) == 2:\n",
    "        channel1 = data[:, 0]\n",
    "        channel2 = data[:, 1]\n",
    "        \n",
    "        # Apply high-pass filter to each channel\n",
    "        try:\n",
    "            filtered_channel1 = highpass_filter(channel1, cutoff_frequency, fs, filter_order, threshold_factor)\n",
    "            filtered_channel2 = highpass_filter(channel2, cutoff_frequency, fs, filter_order, threshold_factor)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return\n",
    "\n",
    "        # Merge channels back into a stereo audio file\n",
    "        filtered_stereo = np.column_stack((filtered_channel1, filtered_channel2))\n",
    "\n",
    "        # Write the filtered audio to a new file\n",
    "        wavfile.write(output_path, fs, filtered_stereo)  # ^^^ path ^^^\n",
    "\n",
    "    else:\n",
    "        print(\"The audio file is not in stereo format.\")\n",
    "\n",
    "\n",
    "# Here, replace desk_path, input_noise_reduction, filter_order, and cutoff_frequency with your actual values.\n",
    "input_path = f'{desk_path}/input/ms_podcast/vr.wav'\n",
    "output_path = f'{desk_path}/output/ms_podcast/vr_noise_reduced_now.wav'\n",
    "input_noise_reduction = 0.05\n",
    "filter_order = 6\n",
    "cutoff_frequency = 100.0\n",
    "\n",
    "adjustable_highpass_filter(input_path, output_path, cutoff_frequency, filter_order, input_noise_reduction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcb6f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7381b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b6a499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "626ec8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.io import wavfile\n",
    "# import numpy as np\n",
    "# import scipy.fftpack\n",
    "\n",
    "# def advanced_noise_reduction(input_path, output_path):\n",
    "#     rate, data = wavfile.read(input_path)\n",
    "#     w = np.fft.fft(data)\n",
    "#     freqs = np.fft.fftfreq(len(w))\n",
    "    \n",
    "#     # Assuming that noise is concentrated at lower frequencies, we apply a high-pass filter\n",
    "#     # Change these values based on your specific needs\n",
    "#     min_freq = 500  # in Hz\n",
    "#     max_freq = 3000  # in Hz\n",
    "    \n",
    "#     # Zero out components that are not within the desired frequency range\n",
    "#     w[(freqs < min_freq)] = 0\n",
    "#     w[(freqs > max_freq)] = 0\n",
    "    \n",
    "#     # Inverse FFT to get the audio back\n",
    "#     filtered_data = np.fft.ifft(w).real.astype(np.int16)\n",
    "    \n",
    "#     # Save the noise-reduced audio\n",
    "#     wavfile.write(output_path, rate, filtered_data)\n",
    "#     print(f\"Noise-reduced audio saved at {output_path}\")  # ^^^ path ^^^\n",
    "\n",
    "# # Example desk_path for demonstration purposes; replace it with your actual desk_path\n",
    "# #desk_path = \"/your/desk/path\"\n",
    "\n",
    "# # Example usage\n",
    "# input_path = f'{desk_path}/input/ms_podcast/vr.wav'\n",
    "# output_path = f'{desk_path}/output/ms_podcast/vr_noise_reduced_2.wav'\n",
    "# advanced_noise_reduction(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55702f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.io import wavfile\n",
    "# import numpy as np\n",
    "# import scipy.fftpack\n",
    "\n",
    "# def advanced_noise_reduction(input_path, output_path):\n",
    "#     rate, data = wavfile.read(input_path)\n",
    "#     w = np.fft.fft(data)\n",
    "#     freqs = np.fft.fftfreq(len(w))\n",
    "    \n",
    "#     # Apply a less aggressive high-pass filter\n",
    "#     min_freq = 100  # in Hz\n",
    "    \n",
    "#     # Zero out components that are not within the desired frequency range\n",
    "#     w[(freqs < min_freq)] = 0\n",
    "    \n",
    "#     # Inverse FFT to get the audio back\n",
    "#     filtered_data = np.fft.ifft(w).real.astype(np.int16)\n",
    "    \n",
    "#     # Save the noise-reduced audio\n",
    "#     wavfile.write(output_path, rate, filtered_data)\n",
    "#     print(f\"Noise-reduced audio saved at {output_path}\")  # ^^^ path ^^^\n",
    "\n",
    "# # Example desk_path for demonstration purposes; replace it with your actual desk_path\n",
    "# #desk_path = \"/your/desk/path\"\n",
    "\n",
    "# # Example usage\n",
    "# input_path = f'{desk_path}/input/ms_podcast/vr.wav'\n",
    "# output_path = f'{desk_path}/output/ms_podcast/vr_noise_reduced_2.wav'\n",
    "# advanced_noise_reduction(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6521bea",
   "metadata": {},
   "source": [
    "# high pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c59b3905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise-reduced audio saved at /Users/yerik/Desktop/output/ms_podcast/vr_noise_reduced_3.wav\n"
     ]
    }
   ],
   "source": [
    "# import librosa\n",
    "# import scipy.signal\n",
    "# from scipy.io.wavfile import write\n",
    "\n",
    "# def simple_highpass_filter(input_path, output_path):\n",
    "#     # Load audio file\n",
    "#     y, sr = librosa.load(input_path, sr=None)\n",
    "    \n",
    "#     # Create a high-pass filter\n",
    "#     sos = scipy.signal.butter(10, 100, 'hp', fs=sr, output='sos')\n",
    "    \n",
    "#     # Apply filter\n",
    "#     filtered_signal = scipy.signal.sosfilt(sos, y)\n",
    "    \n",
    "#     # Save the noise-reduced audio\n",
    "#     write(output_path, sr, filtered_signal.astype(np.int16))\n",
    "#     print(f\"Noise-reduced audio saved at {output_path}\")  # ^^^ path ^^^\n",
    "\n",
    "# # Example desk_path for demonstration purposes; replace it with your actual desk_path\n",
    "# #desk_path = \"/your/desk/path\"\n",
    "\n",
    "# # Example usage\n",
    "# input_path = f'{desk_path}/input/ms_podcast/vr.wav'\n",
    "# output_path = f'{desk_path}/output/ms_podcast/vr_noise_reduced_3.wav'\n",
    "# simple_highpass_filter(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b99218f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed audio saved at /Users/yerik/Desktop/output/ms_podcast/vr_minimal_processed.wav\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "def minimal_processing(input_path, output_path):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(input_path, sr=None)\n",
    "    \n",
    "    # Remove silence\n",
    "    yt, _ = librosa.effects.trim(y)\n",
    "    \n",
    "    # Normalize audio\n",
    "    yt = librosa.util.normalize(yt)\n",
    "    \n",
    "    # Save the audio\n",
    "    write(output_path, sr, (yt * 32767).astype(np.int16))\n",
    "    print(f\"Processed audio saved at {output_path}\")  # ^^^ path ^^^\n",
    "\n",
    "# Example desk_path for demonstration purposes; replace it with your actual desk_path\n",
    "#desk_path = \"/your/desk/path\"\n",
    "\n",
    "# Example usage\n",
    "input_path = f'{desk_path}/input/ms_podcast/vr.wav'\n",
    "output_path = f'{desk_path}/output/ms_podcast/vr_minimal_processed.wav'\n",
    "minimal_processing(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befb7d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "def spectral_subtraction(input_path, output_path, alpha=1.0):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(input_path, sr=None)\n",
    "    \n",
    "    # Compute the short-time Fourier transform (STFT)\n",
    "    D = librosa.stft(y)\n",
    "    \n",
    "    # Estimate the noise\n",
    "    noise_est = np.median(np.abs(D), axis=1)\n",
    "    \n",
    "    # Perform spectral subtraction\n",
    "    D_denoised = D - alpha * noise_est[:, None]\n",
    "    \n",
    "    # Ensure no negative values\n",
    "    D_denoised = np.maximum(D_denoised, 0.0)\n",
    "    \n",
    "    # Inverse STFT to convert back to time domain\n",
    "    y_denoised = librosa.istft(D_denoised)\n",
    "    \n",
    "    # Save the audio\n",
    "    write(output_path, sr, (y_denoised * 32767).astype(np.int16))\n",
    "    print(f\"Noise-reduced audio saved at {output_path}\")  # ^^^ path ^^^\n",
    "\n",
    "# Example desk_path for demonstration purposes; replace it with your actual desk_path\n",
    "desk_path = \"/your/desk/path\"\n",
    "\n",
    "# Example usage\n",
    "input_path = f'{desk_path}/input/ms_podcast/vr.wav'\n",
    "output_path = f'{desk_path}/output/ms_podcast/vr_noise_reduced.wav'\n",
    "spectral_subtraction(input_path, output_path, alpha=2.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacde1cc",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a619b3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting functions.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile functions.py\n",
    "\n",
    "def convert_to_wav(input_path, output_path):\n",
    "    # Supported audio formats by pydub\n",
    "    SUPPORTED_FORMATS = [\"mp3\", \"flv\", \"ogg\", \"mp4\", \"wav\", \"aif\", \"wma\", \"aac\", \"m4a\"]\n",
    "\n",
    "    # Extract the file extension from input_path\n",
    "    file_extension = input_path.split('.')[-1].lower()\n",
    "\n",
    "    # Check if the file format is supported\n",
    "    if file_extension not in SUPPORTED_FORMATS:\n",
    "        print(f\"Unsupported file format: {file_extension}\")\n",
    "        return\n",
    "\n",
    "    # Read the audio file\n",
    "    audio = AudioSegment.from_file(input_path, format=file_extension)\n",
    "\n",
    "    # Convert to WAV\n",
    "    audio.export(output_path, format=\"wav\")\n",
    "    print(f\"File has been converted and saved at {output_path}\")  # ^^^ path ^^^\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------- Function to analyze audio\n",
    "def analyze_audio(audio_path):\n",
    "    #from pydub.utils import mediainfo\n",
    "    audio_info = mediainfo(audio_path)\n",
    "    length_in_seconds = float(audio_info[\"duration\"])\n",
    "    channels = int(audio_info[\"channels\"])\n",
    "    frame_rate = int(audio_info[\"sample_rate\"])\n",
    "\n",
    "    print(f\"Audio duration: {length_in_seconds} seconds\")\n",
    "    print(f\"Channels: {channels}\")\n",
    "    print(f\"Frame rate: {frame_rate} Hz\")\n",
    "    \n",
    "    return length_in_seconds, channels, frame_rate\n",
    "\n",
    "\n",
    "## ------------------------------------------------------------------- Noise Reduction \n",
    "\n",
    "def basic_noise_reduction(input_path, output_path):\n",
    "    # Read the input audio file\n",
    "    rate, data = wavfile.read(input_path)\n",
    "    \n",
    "    # Take a sample of the noise (adjust as needed)\n",
    "    noise_sample = data[:5000]\n",
    "    \n",
    "    # Generate noise profile\n",
    "    noise_profile = np.mean(np.abs(noise_sample))\n",
    "    \n",
    "    # Perform noise reduction: Zero out anything below the profile\n",
    "    reduced_noise_data = np.where(np.abs(data) < noise_profile, 0, data)\n",
    "    \n",
    "    # Save the noise-reduced audio\n",
    "    wavfile.write(output_path, rate, reduced_noise_data.astype(np.int16))\n",
    "    print(f\"Noise-reduced audio saved at {output_path}\")  # ^^^ path ^^^\n",
    "\n",
    "# ## ------------------------------------------------------------------- ADJUSTABLE Noise Reduction \n",
    "\n",
    "\n",
    "def adjustable_noise_reduction(input_path, output_path, threshold_factor=1.0):\n",
    "    # Read the input audio file\n",
    "    rate, data = wavfile.read(input_path)\n",
    "    \n",
    "    # Take a sample of the noise (adjust the range as needed)\n",
    "    noise_sample = data[:5000]\n",
    "    \n",
    "    # Generate noise profile\n",
    "    noise_profile = np.mean(np.abs(noise_sample))\n",
    "    \n",
    "    # Calculate the adjusted threshold\n",
    "    adjusted_threshold = noise_profile * threshold_factor\n",
    "    \n",
    "    # Perform noise reduction: Zero out anything below the adjusted threshold\n",
    "    reduced_noise_data = np.where(np.abs(data) < adjusted_threshold, 0, data)\n",
    "    \n",
    "    # Save the noise-reduced audio\n",
    "    wavfile.write(output_path, rate, reduced_noise_data.astype(np.int16))\n",
    "    print(f\"Noise-reduced audio saved at {output_path}\")  # ^^^ path ^^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a7490f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae02620e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
