{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0746ed0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTN - > TO start coding in this NOTEBOOK & following FNS :::  run ::: hi_jupy()\n",
      "ATTN at the end RUN > py and cleans py ready to be copied >  runpy()\n",
      "ATTN - > TO get all GLOBAL, libs and functions & ALL_DATA inputs, stats, temp, tables files info > db_paths()\n",
      "ATTN - > TO move files from input to curr_direc > move_files(input_folder_path, curr_direc)\n",
      "ATTN - > TO COPY program > copy_files_and_subdirectories(path_2_copy, dest_direc) --- respects original copied\n",
      "ATTN - > TO get all GAME PLANS TO EXPORT ALPHA and BETA programs  > game_plan()\n",
      "define program_folder_name before running runpy()\n"
     ]
    }
   ],
   "source": [
    "exec(open(f\"/Users/yerik/_apple_source/PY/GLOBAL/_1_paths.py\",encoding=\"utf-8\").read()) #paths\n",
    "#direc= curr_direc ;# hi_jupy() \n",
    "# curr_direc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e006ba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a556e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yerik/Desktop/input/ms_podcast/vr.wav'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{desk_path}/input/ms_podcast/vr.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a07b7fd",
   "metadata": {},
   "source": [
    "importing and converting the audio file to WAV format would be to perform an initial analysis of the audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86521f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been converted and saved at /Users/yerik/Desktop/output/ms_podcast/vr.wav\n"
     ]
    }
   ],
   "source": [
    "def convert_to_wav(input_path, output_path):\n",
    "    # Supported audio formats by pydub\n",
    "    SUPPORTED_FORMATS = [\"mp3\", \"flv\", \"ogg\", \"mp4\", \"wav\", \"aif\", \"wma\", \"aac\", \"m4a\"]\n",
    "\n",
    "    # Extract the file extension from input_path\n",
    "    file_extension = input_path.split('.')[-1].lower()\n",
    "\n",
    "    # Check if the file format is supported\n",
    "    if file_extension not in SUPPORTED_FORMATS:\n",
    "        print(f\"Unsupported file format: {file_extension}\")\n",
    "        return\n",
    "\n",
    "    # Read the audio file\n",
    "    audio = AudioSegment.from_file(input_path, format=file_extension)\n",
    "\n",
    "    # Convert to WAV\n",
    "    audio.export(output_path, format=\"wav\")\n",
    "    print(f\"File has been converted and saved at {output_path}\")  # ^^^ path ^^^\n",
    "\n",
    "# Example usage\n",
    "#convert_to_wav(\"input.mp3\", \"output.wav\")\n",
    "\n",
    "convert_to_wav(f'{desk_path}/input/ms_podcast/vr.wav', f'{desk_path}/output/ms_podcast/vr.wav')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4209d901",
   "metadata": {},
   "source": [
    "#### Calculate the length of the audio in seconds and minutes.\n",
    "#### Determine the number of channels (Mono/Stereo).\n",
    "#### Retrieve the frame rate and other properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68b2f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub.utils import mediainfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bb46133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio duration: 165.900952 seconds\n",
      "Channels: 2\n",
      "Frame rate: 44100 Hz\n"
     ]
    }
   ],
   "source": [
    "# Function to analyze audio\n",
    "def analyze_audio(audio_path):\n",
    "    audio_info = mediainfo(audio_path)\n",
    "    length_in_seconds = float(audio_info[\"duration\"])\n",
    "    channels = int(audio_info[\"channels\"])\n",
    "    frame_rate = int(audio_info[\"sample_rate\"])\n",
    "\n",
    "    print(f\"Audio duration: {length_in_seconds} seconds\")\n",
    "    print(f\"Channels: {channels}\")\n",
    "    print(f\"Frame rate: {frame_rate} Hz\")\n",
    "    \n",
    "    return length_in_seconds, channels, frame_rate\n",
    "\n",
    "# Example desk_path for demonstration purposes; replace it with your actual desk_path\n",
    "\n",
    "\n",
    "# Example usage\n",
    "length, channels, frame_rate = analyze_audio(f'{desk_path}/output/ms_podcast/vr.wav')  # ^^^ path ^^^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb67c15",
   "metadata": {},
   "source": [
    "## NOISE REDUTCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4bcb5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise-reduced audio saved at /Users/yerik/Desktop/output/ms_podcast/vr_noise_reduced.wav\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "\n",
    "def basic_noise_reduction(input_path, output_path):\n",
    "    # Read the input audio file\n",
    "    rate, data = wavfile.read(input_path)\n",
    "    \n",
    "    # Take a sample of the noise (adjust as needed)\n",
    "    noise_sample = data[:5000]\n",
    "    \n",
    "    # Generate noise profile\n",
    "    noise_profile = np.mean(np.abs(noise_sample))\n",
    "    \n",
    "    # Perform noise reduction: Zero out anything below the profile\n",
    "    reduced_noise_data = np.where(np.abs(data) < noise_profile, 0, data)\n",
    "    \n",
    "    # Save the noise-reduced audio\n",
    "    wavfile.write(output_path, rate, reduced_noise_data.astype(np.int16))\n",
    "    print(f\"Noise-reduced audio saved at {output_path}\")  # ^^^ path ^^^\n",
    "\n",
    "# Example desk_path for demonstration purposes; replace it with your actual desk_path\n",
    "#desk_path = \"/your/desk/path\"\n",
    "\n",
    "# Example usage\n",
    "input_path = f'{desk_path}/input/ms_podcast/vr.wav'\n",
    "output_path = f'{desk_path}/output/ms_podcast/vr_noise_reduced.wav'\n",
    "basic_noise_reduction(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a736810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise-reduced audio saved at /Users/yerik/Desktop/output/ms_podcast/vr_noise_reduced.wav\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "\n",
    "def adjustable_noise_reduction(input_path, output_path, threshold_factor=1.0):\n",
    "    # Read the input audio file\n",
    "    rate, data = wavfile.read(input_path)\n",
    "    \n",
    "    # Take a sample of the noise (adjust the range as needed)\n",
    "    noise_sample = data[:5000]\n",
    "    \n",
    "    # Generate noise profile\n",
    "    noise_profile = np.mean(np.abs(noise_sample))\n",
    "    \n",
    "    # Calculate the adjusted threshold\n",
    "    adjusted_threshold = noise_profile * threshold_factor\n",
    "    \n",
    "    # Perform noise reduction: Zero out anything below the adjusted threshold\n",
    "    reduced_noise_data = np.where(np.abs(data) < adjusted_threshold, 0, data)\n",
    "    \n",
    "    # Save the noise-reduced audio\n",
    "    wavfile.write(output_path, rate, reduced_noise_data.astype(np.int16))\n",
    "    print(f\"Noise-reduced audio saved at {output_path}\")  # ^^^ path ^^^\n",
    "\n",
    "# Example desk_path for demonstration purposes; replace it with your actual desk_path\n",
    "#desk_path = \"/your/desk/path\"\n",
    "\n",
    "# Example usage with different threshold factors\n",
    "input_path = f'{desk_path}/input/ms_podcast/vr.wav'\n",
    "output_path = f'{desk_path}/output/ms_podcast/vr_noise_reduced.wav'\n",
    "#adjustable_noise_reduction(input_path, output_path, threshold_factor=1.0)  # Default, no extra reduction\n",
    "#adjustable_noise_reduction(input_path, output_path, threshold_factor=1.5)  # More aggressive reduction\n",
    "adjustable_noise_reduction(input_path, output_path, threshold_factor=0.8)  # Less aggressive reduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "626ec8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.io import wavfile\n",
    "# import numpy as np\n",
    "# import scipy.fftpack\n",
    "\n",
    "# def advanced_noise_reduction(input_path, output_path):\n",
    "#     rate, data = wavfile.read(input_path)\n",
    "#     w = np.fft.fft(data)\n",
    "#     freqs = np.fft.fftfreq(len(w))\n",
    "    \n",
    "#     # Assuming that noise is concentrated at lower frequencies, we apply a high-pass filter\n",
    "#     # Change these values based on your specific needs\n",
    "#     min_freq = 500  # in Hz\n",
    "#     max_freq = 3000  # in Hz\n",
    "    \n",
    "#     # Zero out components that are not within the desired frequency range\n",
    "#     w[(freqs < min_freq)] = 0\n",
    "#     w[(freqs > max_freq)] = 0\n",
    "    \n",
    "#     # Inverse FFT to get the audio back\n",
    "#     filtered_data = np.fft.ifft(w).real.astype(np.int16)\n",
    "    \n",
    "#     # Save the noise-reduced audio\n",
    "#     wavfile.write(output_path, rate, filtered_data)\n",
    "#     print(f\"Noise-reduced audio saved at {output_path}\")  # ^^^ path ^^^\n",
    "\n",
    "# # Example desk_path for demonstration purposes; replace it with your actual desk_path\n",
    "# #desk_path = \"/your/desk/path\"\n",
    "\n",
    "# # Example usage\n",
    "# input_path = f'{desk_path}/input/ms_podcast/vr.wav'\n",
    "# output_path = f'{desk_path}/output/ms_podcast/vr_noise_reduced_2.wav'\n",
    "# advanced_noise_reduction(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55702f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.io import wavfile\n",
    "# import numpy as np\n",
    "# import scipy.fftpack\n",
    "\n",
    "# def advanced_noise_reduction(input_path, output_path):\n",
    "#     rate, data = wavfile.read(input_path)\n",
    "#     w = np.fft.fft(data)\n",
    "#     freqs = np.fft.fftfreq(len(w))\n",
    "    \n",
    "#     # Apply a less aggressive high-pass filter\n",
    "#     min_freq = 100  # in Hz\n",
    "    \n",
    "#     # Zero out components that are not within the desired frequency range\n",
    "#     w[(freqs < min_freq)] = 0\n",
    "    \n",
    "#     # Inverse FFT to get the audio back\n",
    "#     filtered_data = np.fft.ifft(w).real.astype(np.int16)\n",
    "    \n",
    "#     # Save the noise-reduced audio\n",
    "#     wavfile.write(output_path, rate, filtered_data)\n",
    "#     print(f\"Noise-reduced audio saved at {output_path}\")  # ^^^ path ^^^\n",
    "\n",
    "# # Example desk_path for demonstration purposes; replace it with your actual desk_path\n",
    "# #desk_path = \"/your/desk/path\"\n",
    "\n",
    "# # Example usage\n",
    "# input_path = f'{desk_path}/input/ms_podcast/vr.wav'\n",
    "# output_path = f'{desk_path}/output/ms_podcast/vr_noise_reduced_2.wav'\n",
    "# advanced_noise_reduction(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6521bea",
   "metadata": {},
   "source": [
    "# high pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c59b3905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise-reduced audio saved at /Users/yerik/Desktop/output/ms_podcast/vr_noise_reduced_3.wav\n"
     ]
    }
   ],
   "source": [
    "# import librosa\n",
    "# import scipy.signal\n",
    "# from scipy.io.wavfile import write\n",
    "\n",
    "# def simple_highpass_filter(input_path, output_path):\n",
    "#     # Load audio file\n",
    "#     y, sr = librosa.load(input_path, sr=None)\n",
    "    \n",
    "#     # Create a high-pass filter\n",
    "#     sos = scipy.signal.butter(10, 100, 'hp', fs=sr, output='sos')\n",
    "    \n",
    "#     # Apply filter\n",
    "#     filtered_signal = scipy.signal.sosfilt(sos, y)\n",
    "    \n",
    "#     # Save the noise-reduced audio\n",
    "#     write(output_path, sr, filtered_signal.astype(np.int16))\n",
    "#     print(f\"Noise-reduced audio saved at {output_path}\")  # ^^^ path ^^^\n",
    "\n",
    "# # Example desk_path for demonstration purposes; replace it with your actual desk_path\n",
    "# #desk_path = \"/your/desk/path\"\n",
    "\n",
    "# # Example usage\n",
    "# input_path = f'{desk_path}/input/ms_podcast/vr.wav'\n",
    "# output_path = f'{desk_path}/output/ms_podcast/vr_noise_reduced_3.wav'\n",
    "# simple_highpass_filter(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b99218f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed audio saved at /Users/yerik/Desktop/output/ms_podcast/vr_minimal_processed.wav\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "def minimal_processing(input_path, output_path):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(input_path, sr=None)\n",
    "    \n",
    "    # Remove silence\n",
    "    yt, _ = librosa.effects.trim(y)\n",
    "    \n",
    "    # Normalize audio\n",
    "    yt = librosa.util.normalize(yt)\n",
    "    \n",
    "    # Save the audio\n",
    "    write(output_path, sr, (yt * 32767).astype(np.int16))\n",
    "    print(f\"Processed audio saved at {output_path}\")  # ^^^ path ^^^\n",
    "\n",
    "# Example desk_path for demonstration purposes; replace it with your actual desk_path\n",
    "#desk_path = \"/your/desk/path\"\n",
    "\n",
    "# Example usage\n",
    "input_path = f'{desk_path}/input/ms_podcast/vr.wav'\n",
    "output_path = f'{desk_path}/output/ms_podcast/vr_minimal_processed.wav'\n",
    "minimal_processing(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befb7d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "def spectral_subtraction(input_path, output_path, alpha=1.0):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(input_path, sr=None)\n",
    "    \n",
    "    # Compute the short-time Fourier transform (STFT)\n",
    "    D = librosa.stft(y)\n",
    "    \n",
    "    # Estimate the noise\n",
    "    noise_est = np.median(np.abs(D), axis=1)\n",
    "    \n",
    "    # Perform spectral subtraction\n",
    "    D_denoised = D - alpha * noise_est[:, None]\n",
    "    \n",
    "    # Ensure no negative values\n",
    "    D_denoised = np.maximum(D_denoised, 0.0)\n",
    "    \n",
    "    # Inverse STFT to convert back to time domain\n",
    "    y_denoised = librosa.istft(D_denoised)\n",
    "    \n",
    "    # Save the audio\n",
    "    write(output_path, sr, (y_denoised * 32767).astype(np.int16))\n",
    "    print(f\"Noise-reduced audio saved at {output_path}\")  # ^^^ path ^^^\n",
    "\n",
    "# Example desk_path for demonstration purposes; replace it with your actual desk_path\n",
    "desk_path = \"/your/desk/path\"\n",
    "\n",
    "# Example usage\n",
    "input_path = f'{desk_path}/input/ms_podcast/vr.wav'\n",
    "output_path = f'{desk_path}/output/ms_podcast/vr_noise_reduced.wav'\n",
    "spectral_subtraction(input_path, output_path, alpha=2.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a619b3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a7490f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae02620e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
